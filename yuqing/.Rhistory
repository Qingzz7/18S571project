catv=names(mpg[,sapply(mpg,is.factor)])
catv
# however, "horsepower" is numeric
catv=catv[2]
mpg[,'horsepower'] = as.numeric(mpg[,'horsepower'])
numv = c(numv, 'horsepower')
summary(mpg)
mpg_num = mpg[,numv]#get plots for numeric variables
boxplot(mpg_num)
pairs(~., data = mpg_num)
#For catgorical variables, we use frequency table.
levels(mpg$carName)
# Too many levels in these two variables. Making contingency table is not a good idea.
mpg_ct=table(mpg$carName)
mpg_ct
mpg_num = mpg[,numv]#get plots for numeric variables
mpg_cor=cor(mpg_num)
mpg_cor
library(corrplot)
corrplot.mixed(mpg_cor)
install.packages("corrplot")
library(corrplot)
corrplot.mixed(mpg_cor)
colnames(mpg)[colSums(mpg=="?")>0]
colnames(mpg)[colSums(is.na(mpg))>0]
summary(mpg)
# 1.Load in the auto mpg data set: https://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data
mpg = read.table('https://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data', header = FALSE)
names(mpg) = c('mpg', 'cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'modelYear', 'origin', 'carName')
summary(mpg)
colnames(mpg)[colSums(is.na(mpg))>0]
df <- read.table('https://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data')
names(df) <- c('mpg', 'cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'modelYear', 'origin', 'carName')
# 2. Identify all of the categorical variables, all of the numeric variables
numVars <- names(which(sapply(df, is.numeric)))
catVars <- names(which(sapply(df, is.factor)))
catVars <- catVars[2]
df[,'horsepower'] <- as.numeric(df[,'horsepower'])
numVars <- c(numVars, 'horsepower')
logicalVars <- names(which(sapply(df, is.logical)))
targetVar <- 'mpg'
varsToRemove <- NA
xVars <- c(catVars, numVars, logicalVars)
xVars <-xVars[!xVars %in% c(targetVar, varsToRemove)]
# Descriptive statistics for the data set
summary(df)
missingDataCols <- colnames(df)[colSums(is.na(df)) > 0]
missingDataCols
View(mpg)
colnames(mpg)[colSums(mpg=="?")>0]
library('caret')
set.seed(2575) # to make result reproducible
itrain = createDataPartition(y = mpg[,1], p = .8,list = FALSE)
mpg_train=mpg[itrain,]
mpg_test=mpg[-itrain,]
stopifnot(nrow(mpg_train) + nrow(mpg_test) == nrow(mpg))# check if missed any row
numv
mpg_trainnum=mpg_train[,numv]
mpg_lm=lm(mpg_trainnum$mpg ~ ., data =mpg_trainnum) #build linear model based on training data
summary(mpg_lm)
library('caret')
trainPct = .8
inTrain <- createDataPartition(y = df[,targetVar], p = trainPct, list = FALSE)
train <- df[inTrain,]
test <- df[-inTrain,]
stopifnot(nrow(train) + nrow(test) == nrow(df))
createModelFormula <- function(targetVar, xVars, includeIntercept = TRUE){
if(includeIntercept){
modelForm <- as.formula(paste(targetVar, "~", paste(xVars, collapse = '+ ')))
} else {
modelForm <- as.formula(paste(targetVar, "~", paste(xVars, collapse = '+ '), -1))
}
return(modelForm)
}
# Remove mpg from numVars
numVars <- numVars[-1]
modelForm <- createModelFormula(targetVar = targetVar, xVars = numVars)
model1 <- lm(modelForm, data = train)
summary(model1)
mpg_testnum=mpg_test[,numv] #numerical varaible in test data set
y=mpg_testnum[,1] #actual target value in test data set
yhat=predict(mpg_lm,newdata = mpg_testnum)[,1] #predicted target value in test data set
rsq=sum((yhat - mean(y))**2)/sum((y - mean(y))**2) #calculate the e square
rsq
mpg[,'horsepower'] = as.numeric(mpg[,'horsepower'])
numv = c(numv, 'horsepower')
class(mpg$horsepower)
summary(mpg)
colnames(mpg)[colSums(mpg=="?")>0]
colnames(mpg)[colSums(is.na(mpg))>0]
colnames(mpg)[colSums(mpg=='?')>0]
mpg_trainnum=mpg_train[,numv]
mpg_lm=lm(mpg_trainnum$mpg ~ ., data =mpg_trainnum) #build linear model based on training data
summary(mpg_lm)
library('caret')
set.seed(2575) # to make result reproducible
itrain = createDataPartition(y = mpg[,1], p = .8,list = FALSE)
mpg_train=mpg[itrain,]
mpg_test=mpg[-itrain,]
stopifnot(nrow(mpg_train) + nrow(mpg_test) == nrow(mpg))# check if missed any row
mpg_trainnum=mpg_train[,numv]
mpg_lm=lm(mpg_trainnum$mpg ~ ., data =mpg_trainnum) #build linear model based on training data
summary(mpg_lm)
summary(model1)
numv
numVars
mpg = read.table('https://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data', header = FALSE)
names(mpg) = c('mpg', 'cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'modelYear', 'origin', 'carName')
catv=names(mpg[,sapply(mpg,is.factor)])
catv
# [1] "horsepower" "carName"
numv=names(mpg[,sapply(mpg,is.numeric)])
numv
# [1]  "mpg"   "cylinders"    "displacement" "weight"    "acceleration" "modelYear"    "origin"
binv=names(mpg[,sapply(mpg,is.logical)])
binv
#character(0)
stopifnot(ncol(catv) + ncol(numv) +ncol(binv) == ncol(mpg)) # check if it includes all types data
# however, "horsepower" is numeric
catv=catv[2]
mpg[,'horsepower'] = as.numeric(mpg[,'horsepower'])
numv = c(numv, 'horsepower')
catv
catVars
numv
numVars
colnames(mpg)[colSums(is.na(mpg))>0]
colnames(df)[colSums(is.na(df))>0]
summary(mpg$horsepower)
View(mpg)
mpg = read.table('https://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data', header = FALSE)
names(mpg) = c('mpg', 'cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'modelYear', 'origin', 'carName')
# 2. Identify all of the categorical variables, all of the numeric variables
# and all of the binary variables.
catv=names(mpg[,sapply(mpg,is.factor)])
catv
# [1] "horsepower" "carName"
numv=names(mpg[,sapply(mpg,is.numeric)])
numv
# [1]  "mpg"   "cylinders"    "displacement" "weight"    "acceleration" "modelYear"    "origin"
binv=names(mpg[,sapply(mpg,is.logical)])
binv
#character(0)
stopifnot(ncol(catv) + ncol(numv) +ncol(binv) == ncol(mpg)) # check if it includes all types data
colnames(mpg)[colSums(is.na(mpg))>0]
View(mpg)
colnames(mpg)[colSums(mpg=="?")>0]
# colunm "horsepower" has missing date
# however, "horsepower" is numeric
catv=catv[2]
mpg[,'horsepower'] = as.numeric(mpg[,'horsepower'])
numv = c(numv, 'horsepower')
catv
numv
numVars
library('caret')
set.seed(2575) # to make result reproducible
itrain = createDataPartition(y = mpg[,1], p = .8,list = FALSE)
mpg_train=mpg[itrain,]
mpg_test=mpg[-itrain,]
stopifnot(nrow(mpg_train) + nrow(mpg_test) == nrow(mpg))# check if missed any row
mpg_trainnum=mpg_train[,numv]
mpg_lm=lm(mpg_trainnum$mpg ~ ., data =mpg_trainnum) #build linear model based on training data
summary(mpg_lm)
mpg_testnum=mpg_test[,numv] #numerical varaible in test data set
y=mpg_testnum[,1] #actual target value in test data set
yhat=predict(mpg_lm,newdata = mpg_testnum)[,1] #predicted target value in test data set
rsq=sum((yhat - mean(y))**2)/sum((y - mean(y))**2) #calculate the e square
rsq
str(mpg_lm)
test[,'yHat'] <- predict(model1,  test)
test$yHat
yhat=predict(mpg_lm,newdata = mpg_testnum)
yhat
rsq=sum((yhat - mean(y))**2)/sum((y - mean(y))**2) #calculate the e square
rsq
summary(mpg_lm)$coef
sigv = names(which(pVals <=.05))
#from above model summary, we can know non-significant variable(alpha = .05)\
pVals = summary(mpg_lm)$coef[,4]
sigv = names(which(pVals <=.05))
sigv = sigv[2:length(sigv)] # Remove intercept
sigv
mpg_lm2=lm(mpg_trainnum$mpg ~ mpg_trainnum$weight+mpg_trainnum$acceleration+mpg_trainnum$modelYear+mpg_trainnum$origin, data = mpg_trainnum)
yhat2=predict(mpg_lm2,newdata = mpg_testnum)
mpg_lm2
summary(mpg_lm2)
mpg_lm2=lm(mpg_trainnum$mpg ~ "weight"+"acceleration"+"modelYear"+"origin", data = mpg_trainnum)
mpg_lm2=lm(mpg_trainnum$mpg ~ weight+acceleration+modelYear+origin, data = mpg_trainnum)
yhat2=predict(mpg_lm2,newdata = mpg_testnum)
rsq2=sum((yhat2 - mean(y))**2)/sum((y - mean(y))**2)
rsq2
mpg_lm3=lm(mpg_train$mpg ~., data = mpg_train)
yhat3=predict(mpg_lm3, newdata = mpg_test)
View(mpg)
mpg[,'horsepower'] = as.numeric(as.character(mpg[,'horsepower']))
mpg = read.table('https://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data', header = FALSE)
names(mpg) = c('mpg', 'cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'modelYear', 'origin', 'carName')
catv=names(mpg[,sapply(mpg,is.factor)])
catv
# [1] "horsepower" "carName"
numv=names(mpg[,sapply(mpg,is.numeric)])
numv
# [1]  "mpg"   "cylinders"    "displacement" "weight"    "acceleration" "modelYear"    "origin"
binv=names(mpg[,sapply(mpg,is.logical)])
binv
#character(0)
stopifnot(ncol(catv) + ncol(numv) +ncol(binv) == ncol(mpg)) # check if it includes all types data
levels(mpg$carName)
# Too many levels in these two variables. Making contingency table is not a good idea.
mpg_ct=table(mpg$carName)
mpg_ct
colnames(mpg)[colSums(mpg=="?")>0]
library('caret')
set.seed(2575) # to make result reproducible
itrain = createDataPartition(y = mpg[,1], p = .8,list = FALSE)
mpg_train=mpg[itrain,]
mpg_test=mpg[-itrain,]
stopifnot(nrow(mpg_train) + nrow(mpg_test) == nrow(mpg))# check if missed any row
mpg_trainnum=mpg_train[,numv]
mpg_lm=lm(mpg_trainnum$mpg ~ ., data =mpg_trainnum) #build linear model based on training data
summary(mpg_lm)
mpg_testnum=mpg_test[,numv] #numerical varaible in test data set
y=mpg_testnum[,1] #actual target value in test data set
yhat=predict(mpg_lm,newdata = mpg_testnum)#predicted target value in test data set
rsq=sum((yhat - mean(y))**2)/sum((y - mean(y))**2) #calculate the e square
rsq
#from above model summary, we can know non-significant variable(alpha = .05)\
pVals = summary(mpg_lm)$coef[,4]
sigv = names(which(pVals <=.05))
sigv = sigv[2:length(sigv)] # Remove intercept
sigv
mpg_lm2=lm(mpg_trainnum$mpg ~ weight+acceleration+modelYear+origin, data = mpg_trainnum)
yhat2=predict(mpg_lm2,newdata = mpg_testnum)
rsq2=sum((yhat2 - mean(y))**2)/sum((y - mean(y))**2)
rsq2
mpg_lm3=lm(mpg_train$mpg ~., data = mpg_train)
yhat3=predict(mpg_lm3, newdata = mpg_test)
#To fix it.
# make "horsepower" is numeric
catv=catv[2]
catv
View(mpg)
mpg[,'horsepower'] = as.numeric(as.character(mpg$horsepower))
numv = c(numv, 'horsepower')
mpg_train2=mpg[itrain,-9]
mpg_test2=mpg[-itrain,-9]
mpg_lm4=lm(mpg_train2$mpg ~., data=mpg_train2)
y4=mpg_test2[,1]
yhat4=predict(mpg_lm4, newdata = mpg_test2)
rsq4=sum((yhat4 - mean(y4))**2)/sum((y4 - mean(y4))**2)
rsq4
mpg$mpg[is.na(mpg$mpg)] = mean(mpg$mpg,na.rm=T) #use mean value to replace missing value in V4
numv
mpg_lm4=lm(mpg_train2$mpg ~., data=mpg_train2)
y4=mpg_test2[,1]
yhat4=predict(mpg_lm4, newdata = mpg_test2)
rsq4=sum((yhat4 - mean(y4))**2)/sum((y4 - mean(y4))**2)
rsq4
yhat4
y4
length(y4)
length(yhat4)
class(yhat4)
class(y4)
sum(yhat4-y4)
is.na(yhat4)
sum(is.na(yhat4))
#fit linear model
mpg_lm4=lm(mpg_train$mpg ~., data=mpg_train)
y4=mpg_test[,1]
yhat4=predict(mpg_lm4, newdata = mpg_test)
class(mpg$horsepower)
summary(mpg$horsepower)
mpg$mpg[is.na(mpg$mpg)] = mean(mpg$mpg,na.rm=T) #use mean value to replace missing value in V4
summary(mpg$horsepower)
mpg$horsepower[is.na(mpg$horsepower)] = mean(mpg$horsepower,na.rm=T) #use mean value to replace missing value in V4
summary(mpg$horsepower)
#fit linear model
mpg_lm4=lm(mpg_train$mpg ~., data=mpg_train)
y4=mpg_test[,1]
yhat4=predict(mpg_lm4, newdata = mpg_test)
#fit linear model
#get new training and testing data
mpg_train2=mpg[itrain,]
mpg_test2=mpg[-itrain,]
mpg_lm4=lm(mpg_train$mpg ~., data=mpg_train2)
y4=mpg_test2[,1]
yhat4=predict(mpg_lm4, newdata = mpg_test2)
mpg_train2=mpg[itrain,-9]
mpg_test2=mpg[-itrain,-9]
mpg_lm4=lm(mpg_train$mpg ~., data=mpg_train2)
y4=mpg_test2[,1]
yhat4=predict(mpg_lm4, newdata = mpg_test2)
rsq4=sum((yhat4 - mean(y4))**2)/sum((y4 - mean(y4))**2)
rsq4
re = lm(mpg$mpg~mpg$modelYear, data=mpg)
re = lm(mpg~modelYear, data=mpg)
plot(mpg$modelYear,mpg$mpg)
abline(re) #add straight regression line
summary(re)
mpg_lmb2=lm(mpg_train2$mpg ~ ., data=mpg_train2)
y5=mpg_test2[,1]
yhat5=predict(mpg_lmb2, newdata = mpg_test2,interval = 'prediction')[,1]
rsq5=sum((yhat5 - mean(y5))**2)/sum((y5 - mean(y5))**2)
rsq5
mpg_lmb=lm(mpg_train2$mpg ~ ., data=mpg_train2)
y5=mpg_test2[,1]
yhat5=predict(mpg_lmb, newdata = mpg_test2,interval = 'prediction')[,1]
r5=sum((yhat5 - mean(y5))**2)/sum((y5 - mean(y5))**2)
r5
summary(mpg_lmb)
# selecting the varaibels showing strong dependencies.
mpg_lmb2=lm(mpg_trainnum$mpg ~ weight+displacement+modelYear+origin, data = mpg_train2)
yhat6=predict(mpg_lmb2,newdata = mpg_train2)
r6=sum((yhat6 - mean(y))**2)/sum((y - mean(y))**2)
r6
r6=sum((yhat6 - mean(y5))**2)/sum((y5 - mean(y5))**2)
r6
mpg_lmb=lm(mpg_train2$mpg ~ ., data=mpg_train2)
y5=mpg_test2[,1]
yhat5=predict(mpg_lmb, newdata = mpg_test2,interval = 'prediction')[,1]
r5=sum((yhat5 - mean(y5))**2)/sum((y5 - mean(y5))**2)
r5
mpg_lmb2=lm(mpg_trainnum$mpg ~ weight+displacement+modelYear+origin, data = mpg_train2)
yhat6=predict(mpg_lmb2,newdata = mpg_train2)
r6=sum((yhat6 - mean(y5))**2)/sum((y5 - mean(y5))**2)
r6
yhat6=predict(mpg_lmb2,newdata = mpg_test2)
r6=sum((yhat6 - mean(y5))**2)/sum((y5 - mean(y5))**2)
r6
df4=read.csv('completeMwrd_03_28_2018.csv',header = TRUE,sep = ',',stringsAsFactors=FALSE)
summary(df4)
dfn=df4[,-1]
summary(dfn)
setwd("~/Documents/GitHub/18S571project/yuqing")
df4=read.csv('completeMwrd_03_28_2018.csv',header = TRUE,sep = ',',stringsAsFactors=FALSE)
summary(df4)
dfn=df4[,-1]
summary(dfn)
# Normalize whole dataset for future models since some models prefer standardized predictors
dfn=data.frame(scale(dfn,center = FALSE,scale=TRUE))
dfn=df4[,-1]
# Normalize whole dataset for future models since some models prefer standardized predictors
dfn=data.frame(scale(dfn[,-8],center = FALSE,scale=TRUE))
View(dfn)
# Normalize whole dataset for future models since some models prefer standardized predictors
dfn[,(1:7)]=data.frame(scale(dfn[,-8],center = FALSE,scale=TRUE))
dfn=df4[,-1]
# Normalize whole dataset for future models since some models prefer standardized predictors
dfn[,(1:7)]=data.frame(scale(dfn[,-8],center = FALSE,scale=TRUE))
View(dfn)
dfn=df4[,-1]
# Normalize whole dataset for future models since some models prefer standardized predictors
dfn[,-8]=data.frame(scale(dfn[,-8],center = FALSE,scale=TRUE))
View(dfn)
summary(dfn)
library('caret')
set.seed(0)
inTrain <- createDataPartition(y = dfn[,'TKN'], p = 0.8, list = FALSE)
train <- dfn[inTrain,]
test <- dfn[-inTrain,]
stopifnot(nrow(train) + nrow(test) == nrow(dfn))
x.train=train[,-6]
y.train=train[,6]
x.test=test[,-6]
y.test=test[,6]
# perform cross-validtion on training data set
controlParameter=trainControl(method = "cv",number = 10,savePredictions = TRUE)
# Basic linear model
lm0 =glm(TKN ~., data = train)
lm_model=train(TKN ~., data=train, method="lm", trControl=controlParameter)
lm_pred=predict(lm_model,test)
forward_model=train(TKN ~., data=train, method = 'leapForward', trControl=controlParameter)
forward_model=train(TKN ~., data=train, method = 'leapForward', trControl=controlParameter)
# calculate the MSE of test data for each model to evaluate its performance
lm_mse=mean((y.test - lm_pred)^2)
lm_model=train(log(TKN) ~log(.), data=train, method="lm", trControl=controlParameter)
lm_pred=predict(lm_model,test)
log()
lm_model=train(log(TKN) ~log(x.train), data=train, method="lm", trControl=controlParameter)
lm_model=train(log(TKN) ~log(train[,(1:7)]), data=train, method="lm", trControl=controlParameter)
lm_model=train(log(TKN) ~.), data=train, method="lm", trControl=controlParameter)
dfn=df4[,-1]
dfn$Location=as.factor(dfn$Location)
summary(dfn)
# Normalize whole dataset for future models since some models prefer standardized predictors
dfn[,-8]=data.frame(scale(dfn[,-8],center = FALSE,scale=TRUE))
# split training and testing data set
library('caret')
set.seed(0)
inTrain <- createDataPartition(y = dfn[,'TKN'], p = 0.8, list = FALSE)
train <- dfn[inTrain,]
test <- dfn[-inTrain,]
stopifnot(nrow(train) + nrow(test) == nrow(dfn))
x.train=train[,-6]
y.train=train[,6]
x.test=test[,-6]
y.test=test[,6]
# perform cross-validtion on training data set
controlParameter=trainControl(method = "cv",number = 10,savePredictions = TRUE)
# Basic linear model
lm0 =glm(TKN ~., data = train)
lm_model=train(TKN ~., data=train, method="lm", trControl=controlParameter)
lm_pred=predict(lm_model,test)
# calculate the MSE of test data for each model to evaluate its performance
lm_mse=mean((y.test - lm_pred)^2)
dfn=df4[,-1]
dfn$Location=as.character(dfn$Location)
summary(dfn)
# Normalize whole dataset for future models since some models prefer standardized predictors
dfn[,-8]=data.frame(scale(dfn[,-8],center = FALSE,scale=TRUE))
# split training and testing data set
library('caret')
set.seed(0)
inTrain <- createDataPartition(y = dfn[,'TKN'], p = 0.8, list = FALSE)
train <- dfn[inTrain,]
test <- dfn[-inTrain,]
stopifnot(nrow(train) + nrow(test) == nrow(dfn))
x.train=train[,-6]
y.train=train[,6]
x.test=test[,-6]
y.test=test[,6]
# perform cross-validtion on training data set
controlParameter=trainControl(method = "cv",number = 10,savePredictions = TRUE)
# Basic linear model
lm0 =glm(TKN ~., data = train)
par(mfrow=c(2,2)) #combine separate plots into one figure
lm_model=train(TKN ~., data=train, method="lm", trControl=controlParameter)
lm_pred=predict(lm_model,test)
# calculate the MSE of test data for each model to evaluate its performance
lm_mse=mean((y.test - lm_pred)^2)
dfn=df4[,-1]
# Normalize whole dataset for future models since some models prefer standardized predictors
dfn[,-8]=data.frame(scale(dfn[,-8],center = FALSE,scale=TRUE))
# split training and testing data set
library('caret')
set.seed(0)
inTrain <- createDataPartition(y = dfn[,'TKN'], p = 0.8, list = FALSE)
train <- dfn[inTrain,]
test <- dfn[-inTrain,]
stopifnot(nrow(train) + nrow(test) == nrow(dfn))
x.train=train[,-6]
y.train=train[,6]
x.test=test[,-6]
y.test=test[,6]
# perform cross-validtion on training data set
controlParameter=trainControl(method = "cv",number = 10,savePredictions = TRUE)
# Basic linear model
lm0 =glm(TKN ~., data = train)
lm_model=train(TKN ~., data=train, method="lm", trControl=controlParameter)
lm_pred=predict(lm_model,test)
# Linear regression model with Forward selection
forward_model=train(TKN ~., data=train, method = 'leapForward', trControl=controlParameter)
# calculate the MSE of test data for each model to evaluate its performance
lm_mse=mean((y.test - lm_pred)^2)
log(dfn)
# Do log tranformation to see if it improves the result
dfn=log(dfn)
View(dfn)
dfn=df4[,-1]
# Scale whole dataset for future models since some models prefer standardized predictors
dfn[,-8]=data.frame(scale(dfn[,-8],center = FALSE,scale=TRUE))
# Do log tranformation to see if it improves the result
dfn[,-(7:8)]=log(dfn[,-(7:8)])
library('caret')
set.seed(0)
inTrain <- createDataPartition(y = dfn[,'TKN'], p = 0.8, list = FALSE)
train <- dfn[inTrain,]
test <- dfn[-inTrain,]
stopifnot(nrow(train) + nrow(test) == nrow(dfn))
x.train=train[,-6]
y.train=train[,6]
x.test=test[,-6]
y.test=test[,6]
# perform cross-validtion on training data set
controlParameter=trainControl(method = "cv",number = 10,savePredictions = TRUE)
lm_model=train(TKN ~., data=train, method="lm", trControl=controlParameter)
lm_pred=predict(lm_model,test)
# calculate the MSE of test data for each model to evaluate its performance
lm_mse=mean((y.test - lm_pred)^2)
dfn=df4[,-1]
# result is better if treat location as numeric
# dfn$Location=as.character(dfn$Location)
summary(dfn)
# Scale whole dataset for future models since some models prefer standardized predictors
dfn[,-8]=data.frame(scale(dfn[,-8],center = FALSE,scale=TRUE))
# Do log tranformation to see if it improves the result
# dfn[,-(7:8)]=log(dfn[,-(7:8)])
# No, the reuslt is worse
# split training and testing data set
library('caret')
set.seed(0)
inTrain <- createDataPartition(y = dfn[,'TKN'], p = 0.8, list = FALSE)
train <- dfn[inTrain,]
test <- dfn[-inTrain,]
stopifnot(nrow(train) + nrow(test) == nrow(dfn))
x.train=train[,-6]
y.train=train[,6]
x.test=test[,-6]
y.test=test[,6]
# perform cross-validtion on training data set
controlParameter=trainControl(method = "cv",number = 10,savePredictions = TRUE)
# models related information: http://topepo.github.io/caret/train-models-by-tag.html
# Basic linear model
lm0 =glm(TKN ~., data = train)
par(mfrow=c(2,2)) #combine separate plots into one figure
plot(lm0)
lm_model=train(TKN ~., data=train, method="lm", trControl=controlParameter)
lm_pred=predict(lm_model,test)
# calculate the MSE of test data for each model to evaluate its performance
lm_mse=mean((y.test - lm_pred)^2)
